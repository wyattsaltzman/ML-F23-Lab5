{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Wide and Deep Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5110, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Read the data\n",
    "data = 'healthcare-dataset-stroke-data.csv'\n",
    "df = pd.read_csv(data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   ever_married       5110 non-null   object \n",
      " 5   work_type          5110 non-null   object \n",
      " 6   Residence_type     5110 non-null   object \n",
      " 7   avg_glucose_level  5110 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     5110 non-null   object \n",
      " 10  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 439.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop id column\n",
    "df = df.drop(['id'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is organized as follows:\n",
    "\n",
    "|Variable | Description|\n",
    "|---------|------------|\n",
    "|gender| Male/Female|\n",
    "|age| continuous|\n",
    "|hypertension| 0=No, 1=Yes|\n",
    "|heart_disease| 0=No, 1=Yes|\n",
    "|ever_married| No/Yes|\n",
    "|work_type| children, Govt_jov, Never_worked, Private, Self-employed|\n",
    "|Residence_type| Rural/Urban|\n",
    "|avg_glucose_level| continuous|\n",
    "|bmi| continuous|\n",
    "|smoking_status| formerly smoked, never smoked, smokes, Unknown|\n",
    "|`stroke`| 0=No, 1=Yes|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "ever_married           0\n",
      "work_type              0\n",
      "Residence_type         0\n",
      "avg_glucose_level      0\n",
      "bmi                  201\n",
      "smoking_status         0\n",
      "stroke                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI is the only column with missing values. 201/5110 ~= 3.93% of the rows don't have BMI; that's not a huge percentage, so we will use KNN imputation to fill in these values.\n",
    "\n",
    "As a note, a large portion of the smoking values - almost 30% - are \"unknown.\" We debated whether or not to treat this as essentially a NaN and drop or impute, but we decided to leave these rows in in case we discover later that the \"unknown\" values skew towards strokes or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   ever_married       5110 non-null   object \n",
      " 5   work_type          5110 non-null   object \n",
      " 6   Residence_type     5110 non-null   object \n",
      " 7   avg_glucose_level  5110 non-null   float64\n",
      " 8   bmi                5110 non-null   float64\n",
      " 9   smoking_status     5110 non-null   object \n",
      " 10  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 439.3+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "# Use k = 3 nearest neighbors based on age, bmi, and average glucose level\n",
    "knn_obj = KNNImputer(n_neighbors=3) \n",
    "attributes_to_impute_with = ['age', 'bmi', 'avg_glucose_level']\n",
    "temp = df[attributes_to_impute_with].to_numpy()\n",
    "temp_imputed = knn_obj.fit_transform(temp)\n",
    "df_imputed = copy.deepcopy(df)\n",
    "df_imputed[attributes_to_impute_with] = temp_imputed\n",
    "df_imputed.dropna(inplace=True)\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Activation\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensorflow dataset\n",
    "batch_size = 64\n",
    "\n",
    "def df_to_dataset(df, shuffle=True, batch_size=batch_size):\n",
    "    df = df.copy()\n",
    "    labels = df.pop('stroke')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "ds = df_to_dataset(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']\n",
      "Feature shape for age is: (64,)\n",
      "Max: tf.Tensor(82.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# print out the data type of each feature\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    # print feature datatype\n",
    "    print('Feature shape for age is:', feature_batch['age'].shape)\n",
    "    print('Max:', max(feature_batch['age']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Product Features\n",
    "\n",
    "Our categorical features are gender, hypertension, heart_disease, ever_married, work_type, and Residence_type. hypertension and heart_disease are already encoded as integers; the other five are strings. When building a keras feature space, we need to consider which categories make sense to combine into cross-product features. After working with this dataset in lab 1, we believe the following combinations should be made:\n",
    "\n",
    "#### TODO: We are discretizing age so we can include in crossing, correct? If not, just do hypertension and heart disease.\n",
    "\n",
    "- **age, hypertension, heart_disease:** Age is the highest correlating risk factor for stroke. The median age for a stroke patient in our dataset is 70. This means that anyone at that age or above should certainly be screened. Additionally, hypertension and heart disease are serious underlying health conditions. They both serve individually as strong risk factors for stroke, and the combination of the two is an even greater risk factor. Age also correlates strongly with hypertension and heart disease, so we believe it makes sense to include them in a cross-product with age. In lab 1, we found that an alarming 25% of patients with both conditions suffered from a stroke. We definitely want to memorize this combination.\n",
    "- **ever_married, Residence_type, work_type:** The three \"lifestyle\" attributes make sense to combine. The lifestyle attributes likely contribute to a person's stress levels. [According to the Heart and Stroke Foundation of Canada](https://www.heartandstroke.ca/healthy-living/reduce-stress/stress-basics), stress levels increase the likelihood for strokes and increase the underlying risk factors for strokes, such as hypertension. Again, in lab 1, we saw that certain combinations of the lifestyle attributes resulted in positive stroke diagnoses at a rate higher than the general population (which is about 5%). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import FeatureSpace\n",
    "\n",
    "\n",
    "# Create the feature space with preprocessing steps applied and crossed features\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "\n",
    "        # Categorical features encoded as string\n",
    "        'gender': FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        'ever_married': FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        'work_type': FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        'Residence_type': FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        'smoking_status': FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "\n",
    "        # Numerical features\n",
    "        'age': FeatureSpace.float_discretized(num_bins=10),\n",
    "\n",
    "        # Numerical features to normalize\n",
    "        'avg_glucose_level': FeatureSpace.float_normalized(),\n",
    "        'bmi': FeatureSpace.float_normalized(),\n",
    "\n",
    "        # Categorical features encoded as integers\n",
    "        'hypertension': FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        'heart_disease': FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "    },\n",
    "    crosses=[\n",
    "        # Is 10 a crossing dimension for age if there are 10 bins?\n",
    "        # Can we do this while initializing the feature space?\n",
    "        # Or Should age be excluded?\n",
    "        FeatureSpace.cross(feature_names=('age', 'hypertension', 'heart_disease'), crossing_dim=10*2*2), \n",
    "        FeatureSpace.cross(feature_names=('ever_married', 'Residence_type', 'work_type'), crossing_dim=2*2*5), \n",
    "    ],\n",
    "    output_mode='concat',\n",
    ")\n",
    "\n",
    "\n",
    "# Create a dataset with the feature space\n",
    "ds_no_labels = ds.map(lambda x, _: x)\n",
    "feature_space.adapt(ds_no_labels)\n",
    "preprocessed_ds = ds.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "preprocessed_ds = preprocessed_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "\n",
    "Our evaluation metric of choice will be F-beta with a larger beta value. For stroke risk classification, we want to minimize the number of false negatives as much as possible. Consider the following two scenarios:\n",
    "\n",
    "- **False positive:** a patient is at low risk, but we classify them as high risk. This means that a patient may undergo unecessary treatment, expenses, and stress if they are screened to visit a doctor, believing they are at high risk for a stroke. However, ultimately the patient is unlikley to suffer from a stroke, so they are still safer despite the false positive.\n",
    "- **False negative:** a patient is at high risk, but we classify them as low risk. This means that a patient falsely believes they are at low risk for a stroke. In this case, key warning signs could go undetected or ignored, and a patient may suffer a stroke without expecting one at all. They would require emergency care, and potentially suffer the most severe consequence possible: death.\n",
    "\n",
    "False negatives and false positives are both bad; however, false negatives are clearly worse. As such, we need an evaluation metric that will tell us if our model is good at avoiding false negatives, while still doing our best to avoid false positives. F-beta can accomplish that for us; if we make beta greater than 1, the addition of the beta term in the denominator weighs recall more importantly than precision. This is what we're looking for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Divison Method\n",
    "\n",
    "When it comes to dividing our data into training and testing, we feel that **stratified k-fold cross validation** makes the most sense. There is a large class imbalance present in our dataset; only approximately 5% (250/5110) of patients actually suffered a stroke, and 95% of patients did not. Using stratified k-fold cross validation will allow for each fold to mirror the original class imbalance present in the dataset. If we were to use non-stratified cross validation or shuffle splits, given the large class imbalance, it's very likely that getting randomized train and test folds could result in 100% non-stroke patients in the fold, which would make for a poor model when it comes to testing. If the model hasn't seen positive stroke patients, it won't know how to classify them. We want to make sure that each fold sees at least a few positive stroke patients. Additionally, given that we only have a moderately sized dataset at 5000 instances, dividing our dataset into training and testing folds will allow us to reuse the data multiple times, instead of trying to generate synthetic samples which could induce noise. In addition, we can take metrics on every iteration of the cross validation process, and then average them or calculate the standard deviation to understand how our model performs across different folds and bound our expectations of it. \n",
    "\n",
    "This is a realistic method to use because in many real-world medical applications, including stroke risk prediction, datasets tend to be imbalanced, with a smaller number of high-risk cases compared to low-risk cases. Using stratified k-fold cross validation to mirror this reality allows us to view how our model would perform on these underrepresented, high-risk cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Residence_type (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " age (InputLayer)            [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " ever_married (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " heart_disease (InputLayer)  [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " hypertension (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " work_type (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " string_categorical_9_prepr  (None, 1)                    0         ['Residence_type[0][0]']      \n",
      " ocessor (StringLookup)                                                                           \n",
      "                                                                                                  \n",
      " float_discretized_2_prepro  (None, 1)                    0         ['age[0][0]']                 \n",
      " cessor (Discretization)                                                                          \n",
      "                                                                                                  \n",
      " string_categorical_7_prepr  (None, 1)                    0         ['ever_married[0][0]']        \n",
      " ocessor (StringLookup)                                                                           \n",
      "                                                                                                  \n",
      " gender (InputLayer)         [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " integer_categorical_4_prep  (None, 1)                    0         ['heart_disease[0][0]']       \n",
      " rocessor (IntegerLookup)                                                                         \n",
      "                                                                                                  \n",
      " integer_categorical_3_prep  (None, 1)                    0         ['hypertension[0][0]']        \n",
      " rocessor (IntegerLookup)                                                                         \n",
      "                                                                                                  \n",
      " smoking_status (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " string_categorical_8_prepr  (None, 1)                    0         ['work_type[0][0]']           \n",
      " ocessor (StringLookup)                                                                           \n",
      "                                                                                                  \n",
      " avg_glucose_level (InputLa  [(None, 1)]                  0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " bmi (InputLayer)            [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " string_categorical_6_prepr  (None, 1)                    0         ['gender[0][0]']              \n",
      " ocessor (StringLookup)                                                                           \n",
      "                                                                                                  \n",
      " string_categorical_10_prep  (None, 1)                    0         ['smoking_status[0][0]']      \n",
      " rocessor (StringLookup)                                                                          \n",
      "                                                                                                  \n",
      " age_X_hypertension_X_heart  (None, 1)                    0         ['float_discretized_2_preproce\n",
      " _disease (HashedCrossing)                                          ssor[0][0]',                  \n",
      "                                                                     'integer_categorical_3_prepro\n",
      "                                                                    cessor[0][0]',                \n",
      "                                                                     'integer_categorical_4_prepro\n",
      "                                                                    cessor[0][0]']                \n",
      "                                                                                                  \n",
      " ever_married_X_Residence_t  (None, 1)                    0         ['string_categorical_7_preproc\n",
      " ype_X_work_type (HashedCro                                         essor[0][0]',                 \n",
      " ssing)                                                              'string_categorical_9_preproc\n",
      "                                                                    essor[0][0]',                 \n",
      "                                                                     'string_categorical_8_preproc\n",
      "                                                                    essor[0][0]']                 \n",
      "                                                                                                  \n",
      " category_encoding_10 (Cate  (None, 2)                    0         ['string_categorical_9_preproc\n",
      " goryEncoding)                                                      essor[0][0]']                 \n",
      "                                                                                                  \n",
      " category_encoding_11 (Cate  (None, 10)                   0         ['float_discretized_2_preproce\n",
      " goryEncoding)                                                      ssor[0][0]']                  \n",
      "                                                                                                  \n",
      " float_normalized_3_preproc  (None, 1)                    3         ['avg_glucose_level[0][0]']   \n",
      " essor (Normalization)                                                                            \n",
      "                                                                                                  \n",
      " float_normalized_4_preproc  (None, 1)                    3         ['bmi[0][0]']                 \n",
      " essor (Normalization)                                                                            \n",
      "                                                                                                  \n",
      " category_encoding_12 (Cate  (None, 2)                    0         ['string_categorical_7_preproc\n",
      " goryEncoding)                                                      essor[0][0]']                 \n",
      "                                                                                                  \n",
      " category_encoding_13 (Cate  (None, 3)                    0         ['string_categorical_6_preproc\n",
      " goryEncoding)                                                      essor[0][0]']                 \n",
      "                                                                                                  \n",
      " category_encoding_14 (Cate  (None, 2)                    0         ['integer_categorical_4_prepro\n",
      " goryEncoding)                                                      cessor[0][0]']                \n",
      "                                                                                                  \n",
      " category_encoding_15 (Cate  (None, 2)                    0         ['integer_categorical_3_prepro\n",
      " goryEncoding)                                                      cessor[0][0]']                \n",
      "                                                                                                  \n",
      " category_encoding_16 (Cate  (None, 4)                    0         ['string_categorical_10_prepro\n",
      " goryEncoding)                                                      cessor[0][0]']                \n",
      "                                                                                                  \n",
      " category_encoding_17 (Cate  (None, 5)                    0         ['string_categorical_8_preproc\n",
      " goryEncoding)                                                      essor[0][0]']                 \n",
      "                                                                                                  \n",
      " category_encoding_18 (Cate  (None, 40)                   0         ['age_X_hypertension_X_heart_d\n",
      " goryEncoding)                                                      isease[0][0]']                \n",
      "                                                                                                  \n",
      " category_encoding_19 (Cate  (None, 20)                   0         ['ever_married_X_Residence_typ\n",
      " goryEncoding)                                                      e_X_work_type[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 92)                   0         ['category_encoding_10[0][0]',\n",
      " )                                                                   'category_encoding_11[0][0]',\n",
      "                                                                     'float_normalized_3_preproces\n",
      "                                                                    sor[0][0]',                   \n",
      "                                                                     'float_normalized_4_preproces\n",
      "                                                                    sor[0][0]',                   \n",
      "                                                                     'category_encoding_12[0][0]',\n",
      "                                                                     'category_encoding_13[0][0]',\n",
      "                                                                     'category_encoding_14[0][0]',\n",
      "                                                                     'category_encoding_15[0][0]',\n",
      "                                                                     'category_encoding_16[0][0]',\n",
      "                                                                     'category_encoding_17[0][0]',\n",
      "                                                                     'category_encoding_18[0][0]',\n",
      "                                                                     'category_encoding_19[0][0]']\n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   5952      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    33        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8071 (31.54 KB)\n",
      "Trainable params: 8065 (31.50 KB)\n",
      "Non-trainable params: 6 (32.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m inference_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m inference_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrainin\u001b[49m\n\u001b[0;32m     21\u001b[0m plot_model(training_model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m            rankdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m, expand_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainin' is not defined"
     ]
    }
   ],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "# Build the model\n",
    "x = keras.layers.Dense(64, activation='relu')(encoded_features)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# this expects features that are already transformed\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# this expects features that are not transformed\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)\n",
    "inference_model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "inference_model.summary()\n",
    "\n",
    "trainin\n",
    "\n",
    "plot_model(training_model, show_shapes=True, show_layer_names=True, to_file='model.png',\n",
    "           rankdir='LR', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use this methodology when actually running the model.\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "# from sklearn.metrics import fbeta_score\n",
    "\n",
    "# clf = training_model\n",
    "# cv = StratifiedKFold(n_splits=10)\n",
    "# scorer = make_scorer(fbeta_score, beta=2)\n",
    "# per_fold_eval_criteria = cross_val_score(estimator=clf, X=preprocessed_ds, y=y, cv=cv, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
